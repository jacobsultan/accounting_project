{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import sys\n",
    "sys.path.append(\"ACC_PROJECT\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from fastai.tabular.all import *\n",
    "from fastbook import cluster_columns\n",
    "from dtreeviz.trees import *\n",
    "import torch as t\n",
    "\n",
    "# Import custom functions\n",
    "from functions.model_evaluator import (\n",
    "    evaluation,\n",
    ") \n",
    "\n",
    "from functions.value_encoding import DataEncoder\n",
    "\n",
    "\n",
    "# Load the dataset and select relevant columns\n",
    "df = pd.read_csv(\"processed_data.csv\", low_memory=False)\n",
    "df.drop(columns=\"description\", inplace=True)\n",
    "\n",
    "\n",
    "# Check for GPU availability and set the device accordingly\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and validation sets with stratification\n",
    "df_wo_valid, df_valid = train_test_split(\n",
    "    df, test_size=0.05, random_state=1, stratify=df.label\n",
    ")\n",
    "df_wo_valid = df_wo_valid.reset_index()\n",
    "df_wo_valid.drop(columns=\"index\", inplace=True)\n",
    "df_valid = df_wo_valid.reset_index()\n",
    "df_valid.drop(columns=\"index\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data for model training\n",
    "encoder = DataEncoder(df)  # Initialize with the entire dataset\n",
    "encoded_training = encoder.transform(df_wo_valid)\n",
    "encoded_validation = encoder.transform(df_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the encoded training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = encoder.split_data(\n",
    "    encoded_training, test_size=0.2, random_state=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the shapes of the split data\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Decision Tree Classifier\n",
    "m = DecisionTreeClassifier(max_leaf_nodes=12)\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "_ = tree.plot_tree(m, feature_names=X_train.columns, filled=True)\n",
    "\n",
    "# Printing the accuracy of the Decision Tree prediction\n",
    "print(\"decision tree prediction\", (m.predict(X_test) == y_test).sum() / len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate feature importance for Random Forest\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame(\n",
    "        {\"cols\": df.columns, \"imp\": m.feature_importances_}\n",
    "    ).sort_values(\"imp\", ascending=False)\n",
    "\n",
    "\n",
    "fi = rf_feat_importance(m, X_train)\n",
    "fi[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform grid search for optimal hyperparameters\n",
    "def optimal_param_search(model, param_grid):\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    optimal_params = grid_search.best_params_\n",
    "    print(\"Best Score = \", grid_search.best_score_)\n",
    "    print(\"Optimal Parameters:\", optimal_params)\n",
    "    return optimal_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\"C\": [0.1, 1, 10, 100], \"max_iter\": [100, 1000, 10000]}\n",
    "\n",
    "optimal_params_lr = optimal_param_search(LogisticRegression(), param_grid_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_optimal = LogisticRegression(**optimal_params_lr)\n",
    "lr_optimal.fit(X_train, y_train)\n",
    "evaluation(lr_optimal, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [3, 5, 11, 19],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "optimal_params_knn = optimal_param_search(KNeighborsClassifier(), param_grid_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining Gradient Boosting Machine\n",
    "knn_optimal = KNeighborsClassifier(**optimal_params_knn)\n",
    "knn_optimal.fit(X_train, y_train)\n",
    "evaluation(knn_optimal, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001],\n",
    "    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "}\n",
    "optimal_params_svm = optimal_param_search(SVC(), param_grid_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_optimal = SVC(**optimal_params_svm)\n",
    "svm_optimal.fit(X_train, y_train)\n",
    "evaluation(svm_optimal,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for Decision Tree\n",
    "param_grid_dt = {\n",
    "    \"max_depth\": [5, 10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20, 40],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "}\n",
    "optimal_params_dt = optimal_param_search(DecisionTreeClassifier(), param_grid_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_optimal = DecisionTreeClassifier(**optimal_params_dt)\n",
    "dt_optimal.fit(X_train, y_train)\n",
    "evaluation(dt_optimal, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "}\n",
    "\n",
    "optimal_params_rf = optimal_param_search(RandomForestClassifier(), param_grid_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_optimal = RandomForestClassifier(**optimal_params_rf)\n",
    "rf_optimal.fit(X_train, y_train)\n",
    "evaluation(rf_optimal,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameter grid for Gradient Boosting Machine\n",
    "param_grid_gbm = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "optimal_params_gbm = optimal_param_search(GradientBoostingClassifier(), param_grid_gbm )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_optimal = GradientBoostingClassifier(**optimal_params_gbm)\n",
    "gbm_optimal.fit(X_train, y_train)\n",
    "evaluation(gbm_optimal,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance from the GBM model\n",
    "feature_importance = gbm_optimal.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Creating a DataFrame for feature importances\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": features, \"Importance\": feature_importance}\n",
    ")\n",
    "\n",
    "# Sorting the DataFrame based on importance\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by=\"Importance\", ascending=False\n",
    ")\n",
    "\n",
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df)\n",
    "plt.title(\"GBM Model Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_confidence_threshold(model, X_test, y_test, probabilities, threshold):\n",
    "    # Initialize counters\n",
    "    correct_above_threshold = 0\n",
    "    correct_below_threshold = 0\n",
    "    incorrect_above_threshold = 0\n",
    "    incorrect_below_threshold = 0\n",
    "\n",
    "    # Loop over all instances in the test set\n",
    "    for i in range(len(X_test)):\n",
    "        # Get the predicted class and the maximum probability (confidence)\n",
    "        predicted_class = model.classes_[np.argmax(probabilities[i])]\n",
    "        max_probability = max(probabilities[i])\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        is_correct = predicted_class == y_test.iloc[i]\n",
    "\n",
    "        # Increment counters based on confidence and correctness\n",
    "        if max_probability >= threshold:\n",
    "            if is_correct:\n",
    "                correct_above_threshold += 1\n",
    "            else:\n",
    "                incorrect_above_threshold += 1\n",
    "        else:\n",
    "            if is_correct:\n",
    "                correct_below_threshold += 1\n",
    "            else:\n",
    "                incorrect_below_threshold += 1\n",
    "\n",
    "    return (\n",
    "        correct_above_threshold,\n",
    "        correct_below_threshold,\n",
    "        incorrect_above_threshold,\n",
    "        incorrect_below_threshold,\n",
    "    )\n",
    "\n",
    "\n",
    "# Set a confidence threshold (for example, 70%)\n",
    "threshold = 0.8\n",
    "\n",
    "# Analyze for GBM model\n",
    "results_gbm = analyze_confidence_threshold(\n",
    "    gbm_optimal, X_test, y_test, probabilities_gbm, threshold\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\n",
    "    \"GBM Results (Correct Above, Correct Below, Incorrect Above, Incorrect Below):\",\n",
    "    results_gbm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilusproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
